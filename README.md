# TFG-II-Eduardo-Molina-Velazquez: Study on the effect on equity of recommendation algorithms for electronic platforms of participatory budgets
## Summary
This repository contains the code and the data used in the development of the Final Degree Project (TFG) entitled "Estudio sobre el efecto en la equidad de algoritmos de recomendación para plataformas electrónicas de presupuestos participativos" (Study on the effect on equity of recommendation algorithms for electronic platforms of participatory budgets). 

The project was carried out by Eduardo Molina Velázquez, student of the Bachelor's Double Degree in Mathematics and Computer Science & Engineering at the Universidad Autónoma de Madrid (UAM). This project was supervised by Dr. Iván Cantador Gutiérrez and Dr. Alejandro Bellogín Kouki, both professors at the Department of Computer Science of the UAM. This study is a continuation of the work carried out by the research of another student, Marina Alonso Cortés, who developed a recommendation algorithm for participatory budgeting platforms. Their code, which is included in this repository, is avaiable in the [official repository](https://github.com/malonsocortes/fairness-eparticipation-recsys?tab=readme-ov-file#fairness-eparticipation-recsys).

## How to use this repository
The repository is organized as follows:
- ``Code``: Contains the code and results used in the project for creating the Apache Lucene Index and the categorization of the proposals into NIMBY and minority:
    - ``run1_proposal_annotator.ps1``: This script processes the database and it generates some csv files which map the different proposals on the database to the different categories and subcategories specified in the vocabulary defined for each city and year. The vocabulary is avaiable in ``Code/Apache_Lucene_Index/data/results/``.
    - ``run2_counting_proposals.ps1``: This script processes csv generated by run1_proposal_annotator.py and it generates a csv file with the number of proposals per category (NIMBY/minority) and subcategory.
    - ``run3_counting_clean_proposals.ps1``: This script processes csv generated by run_annotator.py and it generates a csv file with the number of proposals per category and subcategory, but this time without repetitions, i.e., if a proposal is in two categories, it will only be counted once in the category with the highest score.
    - ``all_excel.bas``: This is a Visual Basic script that processes the csv files generated by run3_counting_clean_proposals.ps1 and generates an Excel file with the results of the categorization for each city and year. This results are are avaiable in ``Code/GeneratedExcels/``.

- ``Recommendations``: data and results of the recommendation process.
    - ``Recommendations/data``: Contains one Excel file with all the results of the recommendation process (original metrics + fairness metrics for all mitigation strategies).
    - ``Recommendations/src``: Contains two main folders: python and jupyter:
        - ``Recommendations/src/jupyter``: Contains the Jupyter notebooks used in the project:
            - ``1_preprocessing.ipynb`` This notebook preprocesses all the data and generates the different matrices used in the recommendation process, as well as creating the neighborhoods for the different cities and years.
            - ``2_train_recommend.ipynb``: Guide to see how to use the recommendation algorithm. It is executed but the real results were generated with the different scripts in the ``python`` folder.
            - ``3_post_recommend.ipynb``: Generates legible recommendations for each algorithm.
            - ``4_fairness.ipynb``: Guide and example of how to generate the fairness metrics. The real results were generated with the different scripts in the ``python`` folder.
            - ``5_strategies.ipynb``: Analysis of the different matrices in order to create the different mitigation strategies. It generates the different matrices used in the recommendation process. 
        - ``Recommendations/src/python``: Contains the code used to generate the recommendations and the metrics for each mitigation strategy. The code is organized in different scripts:
            - ``Recommendations/src/python/implicit_extend``: code from the github repository of recommendation algorithms mentioned above.
            - ``main_1_grid.py``: Generates the different metrics for each mitigation strategy (including basic strategy).
            - ``main_2_final_metrics.py``: Generates the different csvs and htmls files with the results of each city, year and mitigation strategy.
            - ``main_3_recommend.py``: This script generates the final recommendations.
            - ``main_4_fairness.py``: This script generates the fairness metrics for each mitigation strategy.
            - ``csv_final.py``: Generates the final csv with all the results of the recommendation process (recommendation metrics + fairness metrics for all mitigation strategies).
            - The rest of the scripts are auxiliary scripts used in the project.
